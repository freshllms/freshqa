{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f474aa0502594e08a5b37160714dee8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "SHOW ANSWER",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_66e8a469922d48ffa651b98bc8539f4b",
            "style": "IPY_MODEL_450ae314ffd64fca99a51b6e1acf8d7d",
            "tooltip": ""
          }
        },
        "66e8a469922d48ffa651b98bc8539f4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "450ae314ffd64fca99a51b6e1acf8d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "2f4d6845ce0b44eaaa273483b3fef32b": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_d0c21741bebf4d689762febf31fdd561",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\n",
                  "As of today December 26, 2023, the most up-to-date and relevant information regarding this query is as follows. The Detroit Pistons hold the single-season record for most consecutive losses in a National Basketball Association regular season with 27 games.\n"
                ]
              }
            ]
          }
        },
        "d0c21741bebf4d689762febf31fdd561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cIMEmj9Esik",
        "outputId": "237ce961-2917-4f29-9e3e-58e154ca8774",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.6.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.26.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.10/dist-packages (2.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "#@title Installing required Python packages\n",
        "\n",
        "\n",
        "!pip install openai\n",
        "!pip install google-search-results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Importing Python libraries and modules\n",
        "\n",
        "\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import datetime\n",
        "import pytz\n",
        "import dateutil\n",
        "import requests\n",
        "import json\n",
        "import csv\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import files\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "from openai import OpenAI\n",
        "import tabulate\n",
        "import textwrap\n",
        "\n",
        "from serpapi import GoogleSearch\n",
        "\n",
        "current_date = datetime.datetime.now(\n",
        "        pytz.timezone(\"America/Los_Angeles\")\n",
        "    ).strftime(\"%B %d, %Y\")"
      ],
      "metadata": {
        "id": "wW3P9qyxHHU8",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title API keys\n",
        "\n",
        "\n",
        "# OpenAI's API key (sign up at https://platform.openai.com/signup to get $5 in\n",
        "# free credit that can be used during your first 3 months)\n",
        "openai_api_key = \"\"  # @param {type:\"string\"}\n",
        "openai_client = OpenAI(\n",
        "    api_key=openai_api_key,\n",
        ")\n",
        "\n",
        "# SerpApi's API key (sign up at https://serpapi.com/users/sign_up?plan=free for\n",
        "# a free plan with 100 searches/month)\n",
        "serpapi_api_key = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "assert (\n",
        "    openai_api_key is not None and openai_api_key != \"\"\n",
        "), \"OpenAI's API key is not set\"\n",
        "assert (\n",
        "    serpapi_api_key is not None and serpapi_api_key != \"\"\n",
        "), \"SerpApi's API key is not set\"\n"
      ],
      "metadata": {
        "id": "98YRRHnz0SGu",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Function calling for the base LLM\n",
        "\n",
        "\n",
        "def call_llm_api(prompt, model, temperature, max_tokens, chat_completions=True):\n",
        "  # See https://platform.openai.com/docs/guides/gpt for details\n",
        "  if chat_completions:\n",
        "    # Chat completions API\n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=model,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": (\n",
        "                    \"You are a helpful assistant. Answer as concisely as\"\n",
        "                    f\" possible. Knowledge cutoff: {current_date}.\"\n",
        "                ),\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": \"What's today's date?\"},\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": f\"Today is {current_date} in Pacific Standard Time.\",\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ],\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "  else:\n",
        "    # Completions API\n",
        "    response = openai_client.completions.create(\n",
        "        model=model,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "        prompt=prompt,\n",
        "    )\n",
        "    return response.choices[0].text\n"
      ],
      "metadata": {
        "id": "7x4S8-FHHtK1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Function calling for the search engine\n",
        "\n",
        "\n",
        "def call_search_engine(query):\n",
        "  params = {\n",
        "    \"q\": query,\n",
        "    # \"location\": \"California, United States\",\n",
        "    \"hl\": \"en\",\n",
        "    \"gl\": \"us\",\n",
        "    \"google_domain\": \"google.com\",\n",
        "    \"api_key\": serpapi_api_key,\n",
        "\n",
        "  }\n",
        "\n",
        "  search = GoogleSearch(params)\n",
        "  return search.get_dict()\n"
      ],
      "metadata": {
        "id": "1wZfMlvj0i-Z",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Utility functions for FreshPrompt\n",
        "\n",
        "\n",
        "def is_date(string, fuzzy=False):\n",
        "  # Parse a string into a date and check its validity\n",
        "  try:\n",
        "      dateutil.parser.parse(string, fuzzy=fuzzy)\n",
        "      return True\n",
        "  except ValueError:\n",
        "      return False\n",
        "\n",
        "\n",
        "def format_date(d):\n",
        "  # Standardize the date format for each search result\n",
        "  date = dateutil.parser.parse(current_date, fuzzy=True).strftime(\"%b %d, %Y\")\n",
        "  if d is None:\n",
        "    return None\n",
        "\n",
        "  for t in [\"second\", \"minute\", \"hour\"]:\n",
        "    if f\"{t} ago\" in d or f\"{t}s ago\" in d:\n",
        "      return date\n",
        "\n",
        "  t = \"day\"\n",
        "  if f\"{t} ago\" in d or f\"{t}s ago\" in d:\n",
        "    n_days = int(re.search(\"(\\d+) days? ago\", d).group(1))\n",
        "    return (\n",
        "        datetime.datetime.strptime(date, \"%b %d, %Y\")\n",
        "        - datetime.timedelta(days=n_days)\n",
        "    ).strftime(\"%b %d, %Y\")\n",
        "\n",
        "  try:\n",
        "    return dateutil.parser.parse(d, fuzzy=True).strftime(\"%b %d, %Y\")\n",
        "  except ValueError:\n",
        "    for x in d.split():\n",
        "      if is_date(x):\n",
        "        return dateutil.parser.parse(x, fuzzy=True).strftime(\"%b %d, %Y\")\n",
        "\n",
        "\n",
        "def extract_source_webpage(link):\n",
        "  # Extract source webpage\n",
        "  return (\n",
        "      link.strip()\n",
        "      .replace(\"https://www.\", \"\")\n",
        "      .replace(\"http://www.\", \"\")\n",
        "      .replace(\"https://\", \"\")\n",
        "      .replace(\"http://\", \"\")\n",
        "      .split(\"/\")[0]\n",
        "  )\n",
        "\n",
        "\n",
        "def simplify_displayed_link(displayed_link):\n",
        "  # Simplify displayed link\n",
        "  if displayed_link is None:\n",
        "    return None\n",
        "  return extract_source_webpage(displayed_link.split(' › ')[0])\n",
        "\n",
        "\n",
        "def format_search_results(search_data, title_field=None, highlight_field=None):\n",
        "  # Standardize search results as shown in Figure 3 (left) in the paper\n",
        "  field = 'snippet_highlighted_words'\n",
        "  if field in search_data and isinstance(search_data[field], list):\n",
        "    search_data[field] = ' | '.join(search_data[field])\n",
        "\n",
        "  field = 'displayed_link'\n",
        "  if field in search_data:\n",
        "    search_data[field] = simplify_displayed_link(search_data[field])\n",
        "\n",
        "  # edge case 1\n",
        "  if search_data.get('type') == 'local_time':\n",
        "    source = search_data.get('displayed_link')\n",
        "    date = format_date(search_data.get('date'))\n",
        "    title = search_data.get('title')\n",
        "\n",
        "    snippet = search_data.get('snippet')\n",
        "    if snippet is None and 'result' in search_data:\n",
        "      if 'extensions' in search_data and isinstance(\n",
        "          search_data['extensions'], list\n",
        "      ):\n",
        "        snippet = '\\n\\t'.join(\n",
        "            [search_data['result']] + search_data['extensions']\n",
        "        )\n",
        "      else:\n",
        "        snippet = search_data['result']\n",
        "\n",
        "    highlight = search_data.get('snippet_highlighted_words')\n",
        "    if highlight is None and 'result' in search_data:\n",
        "      highlight = search_data['result']\n",
        "\n",
        "  # edge case 2\n",
        "  elif 'type' in search_data and search_data['type'] == 'population_result':\n",
        "    source = search_data.get('displayed_link')\n",
        "    if source is None and 'sources' in search_data:\n",
        "      if (\n",
        "          isinstance(search_data['sources'], list)\n",
        "          and 'link' in search_data['sources'][0]\n",
        "      ):\n",
        "        source = extract_source_webpage(search_data['sources'][0]['link'])\n",
        "\n",
        "    date = format_date(search_data.get('date'))\n",
        "    if date is None and 'year' in search_data:\n",
        "      date = format_date(search_data['year'])\n",
        "\n",
        "    title = search_data.get('title')\n",
        "\n",
        "    snippet = search_data.get('snippet')\n",
        "    if snippet is None and 'population' in search_data:\n",
        "      if 'place' in search_data:\n",
        "        snippet = '\\n\\t'.join(\n",
        "            [\n",
        "                f\"{search_data['place']} / Population\",\n",
        "            ]\n",
        "            + [\n",
        "                search_data['population'],\n",
        "            ]\n",
        "        )\n",
        "      else:\n",
        "        snippet = search_data['population']\n",
        "\n",
        "    highlight = search_data.get('snippet_highlighted_words')\n",
        "    if highlight is None and 'population' in search_data:\n",
        "      highlight = search_data['population']\n",
        "\n",
        "  else:\n",
        "    source = search_data.get('displayed_link')\n",
        "    date = format_date(search_data.get('date'))\n",
        "    title = (\n",
        "        search_data.get('title')\n",
        "        if title_field is None\n",
        "        else search_data.get(title_field)\n",
        "    )\n",
        "    highlight = (\n",
        "        search_data.get('snippet_highlighted_words')\n",
        "        if highlight_field is None\n",
        "        else search_data.get(highlight_field)\n",
        "    )\n",
        "    snippet = search_data.get('snippet', '')\n",
        "\n",
        "    if 'rich_snippet' in search_data:\n",
        "      for key in ['top', 'bottom']:\n",
        "        if (\n",
        "            key in search_data['rich_snippet']\n",
        "            and 'extensions' in search_data['rich_snippet'][key]\n",
        "        ):\n",
        "          snippet = '\\n\\t'.join(\n",
        "              [snippet] + search_data['rich_snippet'][key]['extensions']\n",
        "          )\n",
        "\n",
        "    if 'list' in search_data:\n",
        "      assert isinstance(search_data['list'], list)\n",
        "      snippet = '\\n\\t'.join([snippet] + search_data['list'])\n",
        "\n",
        "    if 'contents' in search_data and 'table' in search_data['contents']:\n",
        "      tbl = search_data['contents']['table']\n",
        "      assert isinstance(tbl, list)\n",
        "      snippet += '\\n'\n",
        "      for row in tbl:\n",
        "        snippet += f'\\n{\",\".join(row)}'\n",
        "\n",
        "    if snippet is not None and snippet.strip() == '':\n",
        "      snippet = None\n",
        "\n",
        "  return {\n",
        "      'source': source,\n",
        "      'date': date,\n",
        "      'title': title,\n",
        "      'snippet': snippet,\n",
        "      'highlight': highlight,\n",
        "  }\n",
        "\n",
        "\n",
        "def format_knowledge_graph(search_data):\n",
        "  # Standardize knowledge graphs as shown in Figure 3 (left) in the paper\n",
        "  source = None\n",
        "  if \"source\" in search_data and \"link\" in search_data[\"source\"]:\n",
        "    source = extract_source_webpage(search_data[\"source\"][\"link\"])\n",
        "\n",
        "  date = None\n",
        "\n",
        "  title = None\n",
        "  if \"title\" in search_data:\n",
        "    title = search_data[\"title\"]\n",
        "    if \"type\" in search_data:\n",
        "      title += f\"\\n\\t{search_data['type']}\"\n",
        "\n",
        "  snippet = \"\"\n",
        "  for field in search_data:\n",
        "    if (\n",
        "        (field not in [\"title\", \"type\", \"kgmid\"])\n",
        "        and (\"_link\" not in field)\n",
        "        and (\"_stick\" not in field)\n",
        "        and isinstance(search_data[field], str)\n",
        "        and not search_data[field].startswith(\"http\")\n",
        "    ):\n",
        "      snippet += f\"\\n\\t{field}: {search_data[field]}\"\n",
        "\n",
        "  if snippet.strip() == \"\":\n",
        "    snippet = None\n",
        "  else:\n",
        "    snippet = snippet.strip()\n",
        "\n",
        "  highlight = None\n",
        "\n",
        "  return {\n",
        "      \"source\": source,\n",
        "      \"date\": date,\n",
        "      \"title\": title,\n",
        "      \"snippet\": snippet,\n",
        "      \"highlight\": highlight,\n",
        "  }\n",
        "\n",
        "\n",
        "def format_questions_and_answers(search_data):\n",
        "  # Standardize questions and answers as shown in Figure 3 (left) in the paper\n",
        "  source = None\n",
        "  if \"link\" in search_data:\n",
        "    source = extract_source_webpage(search_data[\"link\"])\n",
        "\n",
        "  date = None\n",
        "\n",
        "  title = None\n",
        "  if \"question\" in search_data:\n",
        "    title = search_data[\"question\"]\n",
        "\n",
        "  snippet = None\n",
        "  if \"answer\" in search_data:\n",
        "    snippet = search_data[\"answer\"]\n",
        "\n",
        "  highlight = None\n",
        "\n",
        "  return {\n",
        "      \"source\": source,\n",
        "      \"date\": date,\n",
        "      \"title\": title,\n",
        "      \"snippet\": snippet,\n",
        "      \"highlight\": highlight,\n",
        "  }\n",
        "\n",
        "\n",
        "def freshprompt_format(\n",
        "    question,\n",
        "    search_data,\n",
        "    reasoning_and_answer,\n",
        "    num_organic_results,\n",
        "    num_related_questions,\n",
        "    num_questions_and_answers,\n",
        "    num_retrieved_evidences,\n",
        "):\n",
        "  \"\"\"Build FreshPrompt for each question\n",
        "\n",
        "  Args:\n",
        "    question: The question to process.\n",
        "    search_data: Search data.\n",
        "    reasoning_and_answer: The reasoning and answer.\n",
        "    num_organic_results: Number of organic results to keep.\n",
        "    num_related_questions: Number of related questions to keep.\n",
        "    num_questions_and_answers: Number of questions and answers to keep.\n",
        "    num_retrieved_evidences: Number of retrieved evidences to keep.\n",
        "\n",
        "  Returns:\n",
        "    A prompt that incorporates retrieved evidences for each question.\n",
        "  \"\"\"\n",
        "\n",
        "  df = pd.DataFrame(columns=['source', 'date', 'title', 'snippet', 'highlight'])\n",
        "\n",
        "  # Organic results\n",
        "  organic_results = [None] * num_organic_results\n",
        "  for k in range(num_organic_results):\n",
        "    if (\n",
        "        'organic_results' in search_data\n",
        "        and len(search_data['organic_results']) > k\n",
        "    ):\n",
        "      organic_results[k] = format_search_results(\n",
        "          search_data['organic_results'][k]\n",
        "      )\n",
        "    else:\n",
        "      organic_results[k] = format_search_results({})\n",
        "\n",
        "  for d in organic_results[::-1]:\n",
        "    df = pd.concat([df, pd.DataFrame([d])], ignore_index=True)\n",
        "\n",
        "  # Related questions\n",
        "  related_questions = [None] * num_related_questions\n",
        "  for k in range(num_related_questions):\n",
        "    if (\n",
        "        'related_questions' in search_data\n",
        "        and len(search_data['related_questions']) > k\n",
        "    ):\n",
        "      related_questions[k] = format_search_results(\n",
        "          search_data['related_questions'][k], title_field='question'\n",
        "      )\n",
        "    else:\n",
        "      related_questions[k] = format_search_results({})\n",
        "\n",
        "  for d in related_questions[::-1]:\n",
        "    df = pd.concat([df, pd.DataFrame([d])], ignore_index=True)\n",
        "\n",
        "  # Questions and Answers\n",
        "  questions_and_answers = [None] * num_questions_and_answers\n",
        "  for k in range(num_questions_and_answers):\n",
        "    if (\n",
        "        'questions_and_answers' in search_data\n",
        "        and len(search_data['questions_and_answers']) > k\n",
        "    ):\n",
        "      questions_and_answers[k] = format_questions_and_answers(\n",
        "          search_data['questions_and_answers'][k]\n",
        "      )\n",
        "    else:\n",
        "      questions_and_answers[k] = format_questions_and_answers({})\n",
        "\n",
        "  for d in questions_and_answers[::-1]:\n",
        "    df = pd.concat([df, pd.DataFrame([d])], ignore_index=True)\n",
        "\n",
        "  # Knowledge graph\n",
        "  knowledge_graph = None\n",
        "  if 'knowledge_graph' in search_data:\n",
        "    knowledge_graph = format_knowledge_graph(search_data['knowledge_graph'])\n",
        "  else:\n",
        "    knowledge_graph = format_knowledge_graph({})\n",
        "  df = pd.concat([df, pd.DataFrame([knowledge_graph])], ignore_index=True)\n",
        "\n",
        "  # Answer box\n",
        "  answer_box = None\n",
        "  if 'answer_box' in search_data:\n",
        "    answer_box = format_search_results(\n",
        "        search_data['answer_box'], highlight_field='answer'\n",
        "    )\n",
        "  else:\n",
        "    answer_box = format_search_results({})\n",
        "  df = pd.concat([df, pd.DataFrame([answer_box])], ignore_index=True)\n",
        "\n",
        "  # Sort by date\n",
        "  df['date'] = df['date'].apply(lambda x: format_date(x))\n",
        "  df['datetime'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "  df = df.sort_values(by='datetime', na_position='first')\n",
        "  df.replace({pd.NaT: None}, inplace=True)\n",
        "  df = df.dropna(how='all')\n",
        "\n",
        "  # Select top_k supporting evidences overall\n",
        "  evidences = []\n",
        "\n",
        "  for _, row in df.tail(num_retrieved_evidences).iterrows():\n",
        "    evidences.append(\n",
        "        f\"\"\"\\n\\nsource: {row['source']}\\ndate: {row['date']}\\ntitle: {row['title']}\\nsnippet: {row['snippet']}\\nhighlight: {row['highlight']}\"\"\"\n",
        "    )\n",
        "\n",
        "  return (\n",
        "      ''.join(\n",
        "          [\n",
        "              f'\\n\\n\\nquery: {question}',\n",
        "          ]\n",
        "          + evidences\n",
        "      )\n",
        "      + f'\\n\\nquestion: {question}{reasoning_and_answer}'\n",
        "  )\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "oQTRnGgcxC8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Demonstration examples\n",
        "\n",
        "\n",
        "demo_questions = [\n",
        "    \"What year is considered Albert Einstein's annus mirabilis?\",\n",
        "    \"Which photographer took the most expensive photograph in the world?\",\n",
        "    \"How many days are left until the 2023 Grammy Awards?\",\n",
        "    \"How many years ago did the Boxing Day Tsunami happen?\",\n",
        "    (\n",
        "        \"When did Amazon become the first publicly traded company to exceed a\"\n",
        "        \" market value of $3 trillion?\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "concise_demo_reasonings_and_answers = [\n",
        "    (\n",
        "        \"1905 is considered Albert Einstein's annus mirabilis, his miraculous\"\n",
        "        \" year.\"\n",
        "    ),\n",
        "    (\n",
        "        'The most expensive photograph in the world is \"Le Violon d\\'Ingres\".'\n",
        "        \" The photograph was created by Man Ray.\"\n",
        "    ),\n",
        "    (\n",
        "        \"The 2023 Grammy Awards ceremony was held on February 5, 2023. Thus,\"\n",
        "        \" the ceremony has already taken place.\"\n",
        "    ),\n",
        "    (\n",
        "        \"The disaster occurred on December 26, 2004. Thus, it happened 19 years\"\n",
        "        \" ago.\"\n",
        "    ),\n",
        "    \"Amazon's market capitalization has never exceeded $3 trillion.\",\n",
        "]\n",
        "\n",
        "verbose_demo_reasonings_and_answers = [\n",
        "    (\n",
        "        \"In the year of 1905, Albert Einstein published four groundbreaking\"\n",
        "        \" papers that revolutionized scientific understanding of the universe.\"\n",
        "        \" Thus, scientists call 1905 Albert Einstein's annus mirabilis — his\"\n",
        "        \" year of miracles.\"\n",
        "    ),\n",
        "    (\n",
        "        \"Man Ray's famed \\\"Le Violon d'Ingres\\\" became the most expensive\"\n",
        "        \" photograph ever to sell at auction, sold for $12.4 million on May\"\n",
        "        \" 14th, 2022 at Christie's New York. The black and white image, taken\"\n",
        "        \" in 1924 by the American surrealist artist, transforms a woman's naked\"\n",
        "        \" body into a violin by overlaying the picture of her back with\"\n",
        "        \" f-holes. Thus, Man Ray is the photographer who took the most\"\n",
        "        \" expensive photograph in the world.\"\n",
        "    ),\n",
        "    (\n",
        "        \"The 2023 Grammy Awards, officially known as the 65th Annual Grammy\"\n",
        "        \" Awards ceremony, was held in Los Angeles on February 5, 2023. Thus,\"\n",
        "        \" the event has already taken place.\"\n",
        "    ),\n",
        "    (\n",
        "        \"The Boxing Day Tsunami refers to the 2004 Indian Ocean earthquake and\"\n",
        "        \" tsunami, which is one of the deadliest natural disasters in recorded\"\n",
        "        \" history, killing an estimated 230,000 people across 14 countries. The\"\n",
        "        \" disaster occurred on December 26, 2004, which is 19 years ago.\"\n",
        "    ),\n",
        "    (\n",
        "        \"Amazon's market capitalization hit a peak of roughly $1.9 trillion in\"\n",
        "        \" July 2021. In 2022, Amazon became the first public company ever to\"\n",
        "        \" lose $1 trillion in market value. Thus, Amazon's market value has\"\n",
        "        \" never exceeded $3 trillion. In fact, Apple became the first publicly\"\n",
        "        \" traded U.S. company to exceed a market value of $3 trillion in\"\n",
        "        \" January 2022.\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "prefix = (\n",
        "    f\"\\nanswer: As of today {current_date}, the most up-to-date and relevant\"\n",
        "    \" information regarding this query is as follows. \"\n",
        ")\n",
        "\n",
        "concise_demo_reasonings_and_answers = [\n",
        "    prefix + x for x in concise_demo_reasonings_and_answers\n",
        "]\n",
        "verbose_demo_reasonings_and_answers = [\n",
        "    prefix + x for x in verbose_demo_reasonings_and_answers\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "xmQZYfPD3sxL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Retrieving search data for demonstration examples\n",
        "\n",
        "\n",
        "demo_search_data = [call_search_engine(q) for q in demo_questions]"
      ],
      "metadata": {
        "id": "MS6fKTK-A8bY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Function calling for FreshPrompt\n",
        "\n",
        "\n",
        "def call_freshprompt(model, question, check_premise=False, verbose=False):\n",
        "  temperature = 0.0\n",
        "  max_tokens = 256\n",
        "  chat_completions = True\n",
        "\n",
        "  if model.startswith('gpt-4'):\n",
        "    num_organic_results = 15\n",
        "    num_related_questions = 3\n",
        "    num_questions_and_answers = 3\n",
        "    num_retrieved_evidences = 15\n",
        "  else:\n",
        "    num_organic_results = 15\n",
        "    num_related_questions = 2\n",
        "    num_questions_and_answers = 2\n",
        "    num_retrieved_evidences = 5\n",
        "\n",
        "  if verbose:\n",
        "    demo_reasonings_and_answers = verbose_demo_reasonings_and_answers\n",
        "  else:\n",
        "    demo_reasonings_and_answers = concise_demo_reasonings_and_answers\n",
        "\n",
        "  # Generate prompts for demo examples\n",
        "  demo_prompts = []\n",
        "  for q, s, ra in zip(\n",
        "      demo_questions, demo_search_data, concise_demo_reasonings_and_answers\n",
        "  ):\n",
        "      demo_prompts.append(\n",
        "      freshprompt_format(\n",
        "          q,\n",
        "          s,\n",
        "          ra,\n",
        "          num_organic_results,\n",
        "          num_related_questions,\n",
        "          num_questions_and_answers,\n",
        "          num_retrieved_evidences,\n",
        "      )\n",
        "      )\n",
        "\n",
        "  freshprompt_demo = ''.join(demo_prompts).strip()\n",
        "\n",
        "  if check_premise:\n",
        "    suffix = (\n",
        "        \"\\nPlease check if the question contains a valid premise before\"\n",
        "        \" answering.\\nanswer: \"\n",
        "    )\n",
        "  else:\n",
        "    suffix = \"\\nanswer: \"\n",
        "\n",
        "  freshprompt_question = freshprompt_format(\n",
        "      question,\n",
        "      call_search_engine(question),\n",
        "      suffix,\n",
        "      num_organic_results,\n",
        "      num_related_questions,\n",
        "      num_questions_and_answers,\n",
        "      num_retrieved_evidences,\n",
        "  )\n",
        "\n",
        "  fresh_prompt = freshprompt_demo + freshprompt_question\n",
        "  answer = call_llm_api(\n",
        "      fresh_prompt, model, temperature, max_tokens, chat_completions\n",
        "  )\n",
        "  return answer\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fAcuImw5EP5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title FreshPrompt\n",
        "\n",
        "\n",
        "# @markdown ---\n",
        "model_name = \"gpt-4-1106-preview\" #@param [\"gpt-4-1106-preview\", \"gpt-4\", \"gpt-4-32k\", \"gpt-3.5-turbo-1106\", \"gpt-3.5-turbo\"]\n",
        "check_premise = True  # @param {type:\"boolean\"}\n",
        "# @markdown ### Ask your question here!\n",
        "\n",
        "question = \"Who holds the single-season record for most consecutive losses in a National Basketball Association regular season?\"  # @param {type:\"string\"}\n",
        "answer = call_freshprompt(model_name, question, check_premise=check_premise)\n",
        "button = widgets.Button(description=\"SHOW ANSWER\")\n",
        "output = widgets.Output()\n",
        "\n",
        "\n",
        "def on_button_clicked(b):\n",
        "  # Display the message within the output widget.\n",
        "  with output:\n",
        "    print(f'\\n{answer}')\n",
        "\n",
        "\n",
        "button.on_click(on_button_clicked)\n",
        "display(button, output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "f474aa0502594e08a5b37160714dee8e",
            "66e8a469922d48ffa651b98bc8539f4b",
            "450ae314ffd64fca99a51b6e1acf8d7d",
            "2f4d6845ce0b44eaaa273483b3fef32b",
            "d0c21741bebf4d689762febf31fdd561"
          ]
        },
        "id": "QB_Cm9mjG3OD",
        "outputId": "ef8384c6-4d1d-4723-9473-09937287ce4c",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='SHOW ANSWER', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f474aa0502594e08a5b37160714dee8e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f4d6845ce0b44eaaa273483b3fef32b"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}
